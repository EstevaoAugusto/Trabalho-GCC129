# ‚òï CoffeeNet - Atendimento Inteligente para Cafeterias

Bem-vindo ao **CoffeeNet!** Um sistema distribu√≠do que usa Intelig√™ncia Artificial para melhorar o atendimento, aumentar as vendas e deixar os clientes mais satisfeitos no contexto de Cafeicultura.

---

## üò• A "Dor" ‚Äî Problemas que acontecem em cafeterias

Identificamos tr√™s gargalos principais no atendimento:

* üí∏ **Vendas Perdidas:** O barista, na correria, esquece de oferecer promo√ß√µes ou produtos complementares (upsell), diminuindo o ticket m√©dio.
* üòü **Cliente Ansioso:** O cliente (especialmente em pedidos online) n√£o sabe o status do seu pedido ("Na fila?", "Preparando?"), gerando uma experi√™ncia ruim.
* ü§Ø **Cozinha Confusa:** Comandas de papel e comunica√ß√£o verbal causam erros, atrasos na produ√ß√£o e dificultam a gest√£o.

## ‚ú® A Solu√ß√£o ‚Äî O que o CoffeeNet resolve

* **Chatbot Inteligente:** Anota pedidos usando IA (spaCy) e sugere itens baseado no hist√≥rico do cliente e promo√ß√µes (Gemini).
* **Status em Tempo Real:** O cliente v√™ o status ("Recebido", "Em Produ√ß√£o", "Pronto") mudar automaticamente na tela.
* **Cozinha Organizada:** O pedido √© enviado instantaneamente para um painel digital (Kanban), eliminando erros de comunica√ß√£o.

---

## ü§ì Como Funciona? (A M√°gica por Tr√°s dos Panos)

Explicando como as pe√ßas se encaixam, focando nos conceitos da disciplina:

### Por que isso √© um Sistema Distribu√≠do?

Nosso sistema n√£o √© um programa √∫nico. Ele √© um **conjunto de pe√ßas independentes** (programas menores) que precisam conversar pela rede para funcionar. Pense numa banda:

* O **Backend Principal (FastAPI)** √© o vocalista: ele comanda o show, fala com o p√∫blico (Frontends) e diz o que os outros m√∫sicos devem fazer.
* O **Banco de Dados (PostgreSQL)** √© o baterista: ele guarda o ritmo e a mem√≥ria de tudo.
* A **IA (spaCy)** √© o guitarrista especialista: ele s√≥ faz uma coisa (entender texto), mas faz muito bem.

Eles s√£o programas separados, rodando em "caixas" (cont√™ineres Docker) diferentes, e se comunicam por chamadas de rede (HTTP, SQL). Isso *√©* um sistema distribu√≠do.

### As Nossas Duas IAs (Os "C√©rebros"):

A gente usa duas IAs diferentes, como o professor pediu:

1. **IA 1: O "Tradutor" (spaCy / NLU)**

   * **O que √©?** √â a nossa **IA local, que roda dentro do Docker**. Usamos a biblioteca **spaCy**, que √© uma ferramenta padr√£o de mercado para Processamento de Linguagem Natural (NLU).
   * **Como funciona?** Ela n√£o √© s√≥ um `if/else`. Ela carrega um **modelo de machine learning** (`pt_core_news_sm`) treinado para entender a estrutura do portugu√™s. Quando o usu√°rio digita "dois caf√©s e um p√£o de queijo", a fun√ß√£o dela √© "traduzir" essa bagun√ßa humana para dados que o computador entende, algo como: `[{produto_id: 1, qtd: 2}, {produto_id: 3, qtd: 1}]`.
   * **Por que as `Keywords` s√£o importantes?** As `keywords` (que a gente cadastra no painel da cozinha, tipo "p√£o de queijo, paozinho") s√£o a *ponte*. Elas dizem ao spaCy quais palavras no texto do cliente devem ser mapeadas para um produto real no nosso banco de dados.

2. **IA 2: O "Vendedor Inteligente" (Gemini)**

   * **O que √©?** √â a IA "criativa" e externa (do Google, roda na nuvem).
   * **Como funciona?** O nosso Backend Principal pega o pedido "traduzido" pela IA 1 (ex: `[{cafe, 2}]`), busca seu hist√≥rico no banco (ex: "cliente sempre pede p√£o de queijo") e as promo√ß√µes ativas. A√≠, ele monta um **prompt gigante** (uma ordem) para o Gemini, mais ou menos assim: "MISS√ÉO: O cliente pediu 2 caf√©s, mas esqueceu o p√£o de queijo (que √© favorito dele). Confirme o caf√© e sugira o p√£o de queijo. Responda APENAS como um barista."
   * O Gemini, ent√£o, *gera* o texto da resposta que voc√™ v√™ no chat (ex: "Beleza! 2 caf√©s anotados. Notei que voc√™ esqueceu seu p√£o de queijo hoje... quer adicionar?"). Ele n√£o sabe o que √© um produto ou pre√ßo, ele s√≥ segue a miss√£o que nosso backend deu.

### A M√°gica do Tempo Real (WebSockets)

* **Qual o problema?** Em uma API normal (HTTP), o seu navegador (cliente) tem que *perguntar* pro servidor se algo mudou. (Ex: "Meu pedido t√° pronto?", "N√£o." ... "E agora?", "N√£o."). Isso √© lento e gasta recursos.
* **A Solu√ß√£o (WebSocket):** Pense no WebSocket como um **walkie-talkie** ou uma liga√ß√£o de telefone. O cliente e o servidor abrem um "t√∫nel" de comunica√ß√£o e deixam ele aberto.
* **Como usamos:** Quando a Cozinha aperta o bot√£o "Pronto", o Backend Principal usa esse "t√∫nel" para *avisar* (empurrar a informa√ß√£o) na mesma hora pro navegador do Cliente: "EI, SEU PEDIDO #5 FICOU PRONTO!". √â por isso que o status muda na tela do cliente sem ele precisar dar F5. O mesmo vale para o pedido novo que aparece na tela da Cozinha.

---

## üöÄ Como Rodar o Projeto (Guia para o Time de Front-end)

O backend (API, DB, IA 1) t√° todo "encaixotado" no Docker. O frontend (HTML/JS/CSS) roda localmente na sua m√°quina.

### Pr√©-requisitos

* Git
* Docker e Docker Compose (instalados e rodando)

### 1. Clonar o Reposit√≥rio

```bash
git clone [URL_DO_NOSSO_REPOSITORIO_GIT]
cd coffeenet
```

### 2. Configurar Vari√°veis de Ambiente (Obrigat√≥rio)

Isso √© crucial, sen√£o a IA 2 (Gemini) n√£o funciona.

V√° para a pasta backend/.

Crie um arquivo chamado `.env` (copiando do `env.example` se tiver um, ou criando do zero).

Cole o conte√∫do abaixo nele, substituindo `SUA_CHAVE_API_VEM_AQUI` pela sua chave do Gemini:

```ini
# /coffeenet/backend/.env

# --- Chave da IA (OBRIGAT√ìRIO) ---
GEMINI_API_KEY=SUA_CHAVE_API_VEM_AQUI

# --- Configura√ß√£o da Aplica√ß√£o ---
IA_1_NLU_URL=http://ia_1_nlu:8001
SECRET_KEY=uma_chave_secreta_muito_forte_e_dificil_de_adivinhar_0123456789
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=60

# --- Configura√ß√£o Centralizada do Banco de Dados ---
POSTGRES_USER=coffeenet
POSTGRES_PASSWORD=supersecret
POSTGRES_DB=coffeenet_db
DB_HOST=db
DB_PORT=5432 # Porta INTERNA do Docker

# --- URL do Banco (Gerada automaticamente) ---
DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${DB_HOST}:${DB_PORT}/${POSTGRES_DB}
```

### 3. Subir o Backend (Docker)

Volte para a pasta raiz do projeto (/coffeenet).

Limpe instala√ß√µes antigas (se houver):

```bash
sudo docker compose down -v
```

Construa as imagens e suba os servi√ßos (isso pode demorar um pouco na primeira vez):

```bash
sudo docker compose up --build
```

Aguarde at√© os logs se estabilizarem. Voc√™ ver√° o `seed.py` rodar (criando usu√°rios/produtos) e as mensagens de "Uvicorn running" e "Cliente Gemini inicializado". O backend est√° no ar.

### 4. Rodar o Frontend (Servidor Local)

Voc√™ n√£o pode simplesmente abrir o `index.html` (o navegador vai bloquear). Voc√™ precisa de um servidor local.

**Op√ß√£o A: VS Code (Recomendado)**

* Instale a extens√£o "Live Server".
* Abra a pasta `frontend_client/`, clique com o bot√£o direito no `index.html` e "Open with Live Server".
* Abra a pasta `frontend_kitchen/` (em outra janela), clique com o bot√£o direito no `index.html` e "Open with Live Server".

**Op√ß√£o B: Terminal Python**

Terminal 1 (Cliente):

```bash
cd frontend_client/
python -m http.server 8080
# Acesse http://localhost:8080
```

Terminal 2 (Cozinha):

```bash
cd frontend_kitchen/
python -m http.server 8081
# Acesse http://localhost:8081
```


### üîë Acesso e Testes

* Cliente: [cliente@teste.com](mailto:cliente@teste.com) | Senha: 123
* Cozinha: [cozinha@teste.com](mailto:cozinha@teste.com) | Senha: 123

### üõ†Ô∏è Pr√≥ximos Passos

* **Frontend:** Evoluir a interface (design, usabilidade, componentes).
* **Documenta√ß√£o:** Finalizar a Modelagem de Amea√ßas e a Vis√£o Final P√≥s-Mitiga√ß√£o para o professor.
